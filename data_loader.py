import pandas as pdimport sklearnimport numpy as npimport sklearn.model_selectionfrom tqdm import tqdmfrom sklearn.feature_extraction.text import TfidfVectorizerfrom nltk.stem import PorterStemmerimport reps = PorterStemmer()def filter_function(str):    if str=='' or str=='\n':        return False    else:        return Truedef data_cleaning(dataframe):    n=len(dataframe)    data=np.empty(n, dtype=object)    for i in tqdm(range(n)):        text=dataframe['title'][i]+' '+dataframe['author'][i]+' '+dataframe['text'][i]        text=text.lower()        text=list(filter(filter_function, re.split('[^a-zA-Z]', text)))        text =' '.join([ps.stem(word) for word in text])        data[i]=text    return datadef get_data():    ## data loading    train_path = "data/train.csv"    train_data = pd.read_csv(train_path,keep_default_na=False)    ## data cleaning    train_label=train_data['label']    train_data=data_cleaning(train_data)    ## extract tf-df frequency features    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5, min_df=5, stop_words="english")   ##    # # with n-grams    # tfidf_ngram = TfidfVectorizer(sublinear_tf=True, max_df=0.5, min_df=5, stop_words="english", ngram_range=(1,2))    train_data = vectorizer.fit_transform(train_data)    ## split the dataset into training and validation dataset    X_train, X_valid, y_train, y_valid = sklearn.model_selection.train_test_split(train_data, train_label, random_state=0, test_size=0.2)    return [X_train, X_valid, y_train, y_valid]